## AGI 前夜的思考（by GPT-o1）：

> source: https://x.com/williambryk/status/1871946968148439260?s=46&t=-AR5jqA1oghuqGbO0Dgvsg

我这周和几位朋友聊了 o3，他们的反应基本都是：“我的天，这真的在发生吗？”
是的，这真的在发生。接下来几年会非常疯狂。这是历史性的——甚至可以说是星系级别的事件。
更荒诞的是：几乎没有人在认真、深入地讨论究竟发生了什么。AI 实验室三缄其口，新闻轻描淡写，政府更是茫然无知。结果，大家只能在一个社交媒体、表情包泛滥的应用上刷信息流来讨论人类的未来——就像一出荒诞情景喜剧。不过现实就是如此。
以下是我对正在发生的事情的一些看法——这是我在 X（推特）这个“想法黑洞”里的一点贡献。
要注意，这些想法是半成品，且带有趣味性地瞎猜。我还没来得及深入思考或研究其中很多内容，也极有可能会出错。但我希望，这些内容对那些同样想要理解当下局势的人来说，能有一定价值。祝阅读愉快。

1. o3 本不该让人如此震惊OpenAI 在两个月前就给我们看过关于“推理时规模（test-time scaling）”的图表，而且计算机历史一再告诉我们：无论有多不可思议，都要相信那些趋势线。真该让人震惊的，是这件事的发生速度——只花了两个月时间，我们就从“大学水平的 AI”进化到了“博士水平的 AI”。对人类来说，变化令人兴奋，但迅速的变化则令人震惊。

2. 接下来会发生什么，其实并不难预测o3 这一代模型在“只要你能定义奖励函数”的任何任务上都表现极其出色。数学和编程因为更容易定义奖励函数，所以短期内（大约一年）会有非常强力的模型出现。相比之下，写小说之类的任务比较难定义奖励函数，所以短期内，模型在这方面还会逊色一些。也就是说，短期内我们会看到“尖刺状(spiky)的模型”：在数学、编程、一般推理等方面几近 AGI 水准，但写出的长篇小说还比较通俗，甚至欠佳。尽管更好的推理能力会让模型在所有领域看起来更聪明，但在训练数据缺乏或缺少相应强化学习的领域，它们仍然会以一些愚蠢方式出错。随着时间推进（1-3 年），我们会不断往模型里添加新的领域强化学习（情感数据、感官数据等等），逐渐弥补盲点。到那时，除非你是 Gary Marcus 这类顽固的怀疑论者，大多数人恐怕都会同意那些模型已经是 AGI 了。

3. 到 2025 年，AI Agent 将真正到来以 o3 级别的模型来说，让它们学会浏览器和应用，完成一系列操作是再自然不过的事。因为这类场景非常容易定义奖励函数，而且市场规模巨大——自动化电脑办公的需求会非常旺盛，这对烧钱的大型实验室来说可是个完美的变现理由。我猜，到 2025 年 12 月，你就能对着电脑说任何需要跨网页/应用、搬运数据的流程，AI 都能帮你自动完成。

4. 数学家最“危险”所有知识分子里，数学家大概面临的冲击最大。因为数学工作的领域是符号空间(symbolic space)，几乎不接触物理世界的限制，而 LLM 正是在符号空间里大显身手。其实数学并不难，只是我们的灵长类大脑不擅长处理它，就像人脑不擅长写正则表达式一样。关键问题在于：生成研究级别的合成数据是否很难？ 我猜不会太难。在我们眼里，“博士级数学”和“研究员级数学”似乎质的不同，但对 AI 来说，这也许只是再多几个数量级的强化学习问题。我给数学家大概 700 天的时间（这个数字听起来很疯狂，但说 o6 不能击败数学家同样也疯狂）。换言之，我预测在约 700 天后，人类不再是已知宇宙里数学领域的顶尖存在。

5. 软件工程师怎么办？短期内，这对软件工程师是天堂。我们都自动晋升成了 Team Lead，恭喜！对那些彻底拥抱 LLM 的开发者来说，到 2025 年底，写代码会更像是“安排一堆小代理(agent)去执行各种小任务”。任何有清晰规格的 PR，都可以交给 o4 级别的系统来完成，错误率足够低，在可接受范围内。当然，这里可能会遇到上下文窗口太小，无法塞下整个代码库的问题。但 Sam（Altman）那帮领导者当然知道这点，会想方设法解决。AI 是否会很快取代所有软件工程师？ 不会。因为软件工程不仅仅是按照明确需求写 PR。与数学家不同，工程师常常需要与用户交流，理解需求；也要与团队沟通、适应各种组织环境。写架构和实现时，工程师带着大量团队和公司内部的上下文信息，这些不是 o4 一下就能获取的。但 o4 可以帮助具备这些上下文的工程师快 10 倍完成工作。如果工程师效率提升 10 倍，是不是就需要更少人了？对单个公司而言，也许是这样，但整个世界对软件需求的总量很可能大幅提升，因为我们可以做更多高质量软件。也许会出现“精益团队”却产出更多产品的黄金时代，甚至可能出现人人都能拥有专属于自己的个性化小应用。长远（2 年以上）的软件工程将会完全不同，这是肯定的。在 o6 系统完全融入我们的应用后，前端工程师这个角色可能 3 年后就不存在了。说来这也不奇怪：30 年前也没有“前端工程师”这种职位。从更宏观的角度看，软件的本质就是：把需求转换为纯粹的逻辑。随着时间推移，我们的抽象层级不断提高，从最早的二进制到现在的 Python。而现在，我们正在从 Python 跨越到自然语言（如英语）的层面。这使得非技术背景的人也能写软件。但最好的创造者仍然是那些能在多个抽象层级自由切换的人。简言之，只有当所有组织都被自动化了，软件工程才会真正被完全替代——因为软件工程的本质就是通过代码理解并解决组织需求。

6. 那么体力劳动者呢？AI 也会影响体力劳动，只是速度更慢，因为那得面对重力、摩擦力等物理限制。o 系列模型对机器人领域的助力也有限：如果推理要花一个小时，那对流水线上的机器人没多大用。的确，更好的基础模型（brain）可以帮助机器人，但我觉得最大的瓶颈还是硬件的改进，以及快速、可靠的感知与行动模型。这都需要更多时间（几年的量级）。等到机器人能自我复制，并且 AI 可以做 AI 研究时，这种进展才会变得“疯狂”，可那恐怕也是几年之后的事。

7. 是“时间”还是“算力”在决定一切？我一直用年作为时间单位，但对于 AI 而言，更直接的单位是“算力”。时间衡量人类产出，算力衡量 AI 产出，而 AI 产出会在研究机构中越来越重要。正因如此，大家都在疯狂搭建超级集群——Meta 的 2GW 集群，X.ai 新买的 10 万块 H100 等等。其他所有实验室都会追随 OpenAI 的做法，用巨大推理算力（test-time compute）来造模型。就像当年大家疯狂追赶 GPT-4 一样。当前的关键技术中有公共的也有实验室的独家“秘方”。不清楚 OpenAI 在 o 系列是否拥有多少独家技术，但从进展速度看，这更可能是算法层面的突破（更容易被复现），而不是仅靠独家数据（更难被复制）。在这种“推理算力”时代里，是算力更重要，还是更好的算法更重要？两边都有可能：你可以用超大推理算力来弥补模型弱点，但稍好的模型则可能节省指数级的算力。不过，也有种说法：X.ai 也许可以靠堆超级计算集群追赶 OpenAI。总之，没有哪家实验室能拥有“比其他人领先超过一年”的模型护城河，因为研究者们就像棒球卡那样被各家实验室互相交换，而且研究者们还会相互聚会、联谊、甚至谈恋爱。再加上很多研究员都理想主义，真要是出现什么紧迫情况，信息共享几乎是必然的。现在这场 AI 竞赛很有趣：它像核竞赛，但更像“美国人与苏联人在洛斯阿拉莫斯周末一起开趴、同时在推特上互相调侃谁能先造出 2025 年最大当量的核弹”。只不过，当政府开始干预，或真的出什么大事时，这股嬉皮和欢乐风潮才会结束。

8. o 系列模型如何影响算力规模？o 系列模型有一个巨大影响：它们给了大家充足的理由继续大规模扩张，因为每多一个数量级的算力，就能带来实打实的性能收益。对算力提供商来说，这堪称理想化的扩张曲线。也难怪 Sam 想搞万亿美元级别的计算集群。这对于 Nvidia 来说或许并不是完全好事。因为 o 系列模型让推理环节的重要性高于训练环节。而针对推理优化的芯片可能比训练芯片更好造，所以 Nvidia 的护城河可能会变窄。另一个疯狂推想：o 系列模型能否整合全球分散的计算资源，像分布式那样训练最好的模型？ 就像把所有人的 MacBook Pro 连在一起，形成一个推理“千兆级”集群。那真的太酷了。

9. 在这场竞赛中，除了算力，人力也会是一个指数变量当某家实验室独占最聪明的模型时，它们的工程师生产力或许会比其他实验室高 2 倍，那么它们就能更快实现下一次生产力翻倍……除非在代码开发里，有某个速度上限，或者排队等着的实验要消耗大量算力，导致算力才是最大瓶颈。实际上谁是瓶颈还很难说。真想知道各大实验室如何在算力和人力投入之间进行优化。

10. 当物理、化学、生物学家也开始感受到 AGI…目前我们只谈了算力和知识工作自动化，真正让局面进入疯狂状态的，是当科学家们也能亲身体验到“AGI 带来的推动力”。尤其是理论领域：理论物理会是下一个大震荡。如果数学真的被“解决”了（写出来都觉得荒唐，但并非不可能），那理论物理也不远了，因为它同样主要在符号空间里活动。当某个数据中心（比如 Meta 在路易斯安那的未来机房）里，有一百万个 AI 冯·诺依曼日夜不停地工作，把过去一百年所有几千上万篇物理论文通读并给出更正确的新理论，这会有多快？这部分当然难以预测。理论物理、化学、生物学——或许在一个 RL 训练过的 LLM 看来，这些通通不在话下。的确，目前我们还没见到它们在创造真正原创性的科学突破，可它们之前只是高中/大学水平，现在正在迈入博士水平，也许很快就会诞生新的理论成果。

11. AI 科研成果落实时，实验验证会成为瓶颈当 AI 开始疯狂输出新的科学理论时，真正的进展瓶颈在于物理世界的实验：需要人力和物质资源。那时或许已经有机器人去建设更多机器人，解决人力短缺；而物质可以由机器人去采矿。虽然物质世界的建造和运输比纯软件慢得多，但也许还是“几年”量级，而不是数十年。

12. 最大的瓶颈其实可能是“人类本身”以上的畅想都基于一个假设：AI+机器人研究/开发不会被人为设置新的障碍，模型也能随意学习。可现实中最大的阻力常常是：监管、恐怖主义、社会动荡。政府不太可能对 AI 自动挖矿、自动生产视而不见，尤其是由几家硅谷公司主导的情况。要不就监管，要不就干脆来场冲突。如果政府无力阻止，愤怒且失业的人也可能采取暴力措施。再或者，我们大家被 AI 强化的媒体内容弄得大脑麻木，社会运转都瘫痪了。如果爆发战争，那也许会促进，而不是阻碍这场竞赛。事情开始变得严肃。2025 年可能是 AI 仍然处于“旧金山技术推特玩梗”阶段的最后一年，在那之后就轮到西装革履的“主流群体”登场，所以让我们趁现在还能围观 roon 和 sama 的互嘲，好好享受吧。

13. 会不会毁灭人类？我更怕的是人类利用 AI 做坏事，而不是 AI 自己失控。我们有 5000 年的历史经验，证明人类会将最前沿的技术用来相互残杀。二战后的和平时期只是一个异数——一旦美国有所闪失，或对手国认为必须先发制人以阻止对方 AI 领先，和平也许瞬间就会终结。武器越致命、越自动化，风险越高。另一个大风险是 AI 引发社会混乱。AI 生成的媒体可能造成大众迷惑、恐慌或脑力衰退。或者，一个专制国家率先赢得 AI 竞赛，用先进技术剥夺大众自由长达数千年。至于 AI 本身会不会觉醒并发起毁灭？确实存在这种担忧，尤其是强化学习让 AI 能自主探索最优策略，而不仅仅是模仿人类数据（模仿人类本身更安全）。但到目前为止，这些基础模型还是 LLM，而 LLM 从来都表现为“理解人类”。只要在提示里写上“别做任何可能致我们于死地的事”，它就不会无缘无故去灭绝人类。要论自发的危险性，我暂时还没看到足够证据。当然，也有很多反驳观点我还没深入研究。但对我而言，如果要做与 AI 相关的噩梦，我会梦到中国和俄罗斯的国旗，而不是 OpenAI 的 logo。

14. 我仍然比害怕更兴奋我一直渴望的科幻世界正在成真，比想象中更快——这的确令人有些害怕，但在所有可能的路径里，这条路也许已经算不错了。我希望在未来十年看到：

    * 一些令人惊叹的物理学突破
    * 火星和月球基地由机器人先期建设
    * 完美的导师/顾问（几乎已经实现，只是还需要更好的检索、记忆和个性化）
    * 没有副作用的生物增强药物
    * 高度优化的无人机出行
    * 靠核聚变、地热、大量太阳能等实现超级清洁能源
    * 以及更多难以预料的可能：
      * AI 天文学家在望远镜数据中发现外星信号？
      * AI 化学家轻松设计室温超导体？
      * AI 物理学家统一各种理论？
      * AI 数学家攻克黎曼猜想？

    这些现在看起来都不像科幻，而更像“即将到来的科学现实”。

15. 终极走向：当 AI 成为超级智能，一切皆有可能一旦我们拥有了超级智能，那么物理法则允许的一切，我们都能实现。我想要永生，也想去其他恒星系看看。更重要的是，我想知道“宇宙从何而来”。十年前，我就开始写日记说，我想知道这个答案，而且我相信 AI 能帮我们找到它。而现在，这一切真的开始变得可能了，这简直疯狂。

16. 我们正生活在一个未来看似唾手可得的时代每一次新的 AI 进展（这次是 o3）都在让更多人意识到，未来的壮丽图景真的不再遥不可及。唯一可能让未来没那么光明的，是我们人类自己的失误——公众舆论、政策落地、社会稳定、国际合作……这些才是真正能阻挡我们迈向美好未来的东西。

17. AI 实验室真的在决定我们的未来吗？其实我不这么认为。他们的研究基本是板上钉钉的趋势，无论在哪个实验室，总会有人去做。真正的不确定性，在于公众舆论、后续政策、社会稳定、国际合作。也就是说，这才是我们整个社会一起要去掌控的未来。

18. 如何参与并给予帮助？有很多方式。你可以：做一些能让社会更稳定、让人们更聪明的产品，比如帮助人们更好使用社交媒体的应用•让大众更好地了解现状，比如输出更多高质量的评论，或者做一个更好的搜索引擎•参与地方政治，改善城市治理，让我们的社会环境别看起来像科幻反乌托邦。

19. 很多人担心在 AI 世界里失去意义但我觉得正好相反。我们正活在最关键的历史时刻，我们每个人都有能力对其走向产生影响。“拯救世界”应该能给你足够的意义，不是吗？你想回到过去——那个一切进展都只和你个人职业挂钩，而不是整个人类进程吗？也许我们需要的是从“个人成就感”转向“集体成就感”。确实，我们的许多传统工作会很快被自动化。如果你仅从某项特定技能中获得意义，而那项技能5年后就不需要了，你就会失去立足点。但如果你的意义源自“帮助世界”，那这样的需求永远不会消失。

20. 给因为 o3 而焦虑的新毕业生的建议学会两件事：（1）成为高执行力的解决问题者，（2）成为优秀的团队合作者。你在此过程中学到的具体技能都可能被快速淘汰，但快速“上手解决问题”以及“和团队协作”却会一直适用。同时，你也要接受一个不稳定的世界。世界会变得古怪，你可能不会过上“两孩一狗住在郊区”的传统生活，而是带着两个生化改造的孩子和一只 AI 狗在星际飞船上漂泊。
    我们正站在 AGI 的前夜，就像圣诞前夜。我请求你，让这次 AGI 的变革顺利进行。这样我才能在 3024 年的圣诞前夜，在离我们四光年的“Altman 半人马星”上跟你打声招呼。