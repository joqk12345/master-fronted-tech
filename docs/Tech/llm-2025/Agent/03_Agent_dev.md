## Agent Dev （2）

## Agent application dev 与 LLM Dev 的GAP

- **大语言模型（LLM）的本质缺陷**：
  - **自回归模型的不稳定性**：LLM，如GPT，本质上是自回归模型，通过预测序列中的下一个词来生成文本。这种机制导致了模型输出的不稳定性。即使输入相同的问题，LLM也可能给出不完全相同的答案。这种不稳定性源于模型在训练时内化的一些假设，而这些假设可能是不一致的。
  - **模型内部假设的不确定性**：模型在训练时会形成一些内部的假设，但这些假设是隐含的，难以直接暴露出来。即使通过提示词让模型给出其前提假设，这些假设也未必稳定。
- **人为干预的局限性**：
  - **难以彻底纠正**：即使人类尝试纠正LLM的错误假设，由于没有直接修改模型内部的参数，这些纠正的效果也是不确定的。模型可能会在后续的推理中忽略或弱化这些纠正，因为纠正的“权重”不确定。
  - **人为干预会降低智能体的自主性**：如果需要在智能体运行过程中进行人为干预，这会降低智能体的自主性，使得它无法完全独立地完成任务。
- **人类自身世界观的不稳定性**：
  - **哲学层面缺乏共识**：人类在哲学层面也未能建立稳定的世界观。即使每个人都有自己的人生信条，这些信条也往往无法覆盖所有情况。
  - **难以总结普遍规律**：人类尚未总结出适用于所有情况的普遍规律，这使得为LLM构建稳定的世界观变得异常困难。
  - **不同领域问题的复杂性**：在特定领域内，可以通过微调（fine-tuning）或使用检索增强生成（RAG）等技术为LLM构建相对稳定的世界观，但是如果问题领域扩大，这种方法就会失效，因为很难用有限的规则来约束无限的可能。
- **LLM的训练和应用之间的gap**
  - **Fine-tuning 的局限** 虽然fine-tuning 可以帮助模型在特定领域内获得更好的性能，但它并不一定能解决模型内部世界观不稳定的问题。
  - **应用开发的挑战** 文件中提出， **更重要的是让模型建立稳定的世界观，而不是单纯追求更高的性能指标**。目前的LLM开发主要集中在应用层面，例如如何更好地整合内容、进行推理等，但很少有工作关注如何让LLM建立一个稳定的世界观，这才是根本性的挑战。

总结来说，**“稳定的世界观”之所以难以存在，是因为LLM本身的自回归机制和内部假设的不确定性，以及人类自身在哲学层面也未能建立稳定的世界观**。即使通过人为干预来修正LLM的错误，由于未能修改模型内部的参数，这些修正的效果也往往是不稳定的。因此，为LLM构建一个稳定的世界观是一个非常具有挑战性的问题，它不仅涉及技术层面的挑战，还涉及哲学层面的思考。

## 当前的Agent 开发所处的阶段

当前智能体（Agent）的开发，正处于一个**从“玩一玩”到“商品化”过渡的阶段**，尚未完全达到产品化成熟的阶段。 尽管如此，现在已经是一个入坑并开始实践的好时机。

- **技术方向明确，但挑战仍然存在**:

  - **发展方向明确**：当前智能体的发展方向已经非常明确，行业内对关键技术，如**函数调用（tools calling）、结构化输出（structure output）和推理（reasoning）**，有着广泛的共识。

  - 技术挑战

    ：尽管方向明确，但仍面临许多技术挑战，包括：

    - **大模型的标准化不足**：各厂商的大模型在技术标准和实现方式上存在差异，导致兼容性问题，增加了开发者的负担。
    - **模型小型化和性能效率**：如何提高模型的推理性能，以及如何将大型模型小型化，仍然是亟待解决的问题。
    - **安全问题**：随着智能体应用的扩展，安全问题日益突出，但目前这方面的研究还不够深入。

- **应用开发的主要方向**:

  - **更好的内容整合**：如何更好地整合来自不同来源的内容，例如使用智能体进行信息检索和摘要。
  - **增强推理能力**: 如何使智能体能够进行更复杂的推理，例如使用**智能提示词（smart prompt）**来分解复杂任务。

- **开发现状**:

  - **从“玩一玩”到“商品化”的过渡期**：当前智能体开发仍处于探索阶段，尚未完全实现产品化和成熟化。
  - **鼓励入坑实践**：尽管如此，现在已经是一个开始学习和实践的好时机，通过动手实践可以获得更深刻的理解。

- **大模型厂商的竞争**:

  - **标准之争**：各大厂商为了竞争优势，在技术标准上存在差异，甚至互相“别苗头”，这导致了重复劳动和开发成本的增加。
  - **类似于浏览器大战**：当前大模型领域的竞争状况，类似于当年的浏览器大战，各大厂商都有自己的标准，使得开发者需要做大量兼容性工作。

- **关于“稳定的世界观”的讨论**:

  - **模型的内在假设**:  模型在训练时会形成内在假设，并且这些假设可能不稳定，会导致输出不一致。
  - **人为干预的局限**: 人为的纠正模型假设，因为没有直接修改模型参数，其效果不稳定。
  - **人类自身世界观的局限**: 人类自身也缺乏稳定的世界观，这使得为LLM构建稳定的世界观更加困难。

总而言之，当前的智能体开发领域正处在一个快速发展和变革的时期。虽然还面临着许多挑战，但方向已经明确，并且有许多有价值的研究和实践机会。**开发者现在入坑，开始学习和实践，将有助于在未来的竞争中占据优势**。

## 为什么说现在有当年的浏览器大战的感觉

- **各厂商的差异化竞争**：
  - **不兼容的标准**：像 OpenAI 和 Anthropic 这样的主要厂商，为了保持竞争优势，**故意采取不同的技术标准和方法**。这种做法导致各家模型之间存在不兼容性，使得开发者需要做大量额外工作来兼容不同的系统。
  - **互相别苗头**：各厂商之间存在明显的“别苗头”现象，即一方推出某种技术或标准后，另一方会坚决不采用，而是另起炉灶，推出类似的但不兼容的技术或标准。
  - **重复劳动**: 这种差异化竞争导致很多开源的第三方库，比如 PhiData，必须要做大量工作来兼容不同但是类似的技术体系。
- **技术标准之争**：
  - **标准化问题**：LLM 领域缺乏统一的标准，各厂商都在推出自己的解决方案，这使得开发者难以在不同的模型之间进行迁移和复用。
  - **可编程能力**:  目前，大型模型已经不再以与人聊天为主要目标，而是转向提供可编程能力，但这些可编程能力的标准化仍是一个问题。
- **开源社区的挑战**：
  - **兼容性负担**：由于各厂商的技术标准不统一，开源社区的开发者需要花费大量精力来做兼容工作，以支持不同的模型和平台。
  - **开源框架的努力**：像 file data 这样的开源框架，为了兼容不同厂商的模型，不得不做大量的适配工作，这增加了开发和维护的成本。
- **历史的相似性**：
  - **浏览器大战的影子**：当前 LLM 领域的竞争格局与当年的浏览器大战非常相似，当时各浏览器厂商为了争夺市场份额，也纷纷推出自己的标准，导致开发者需要为不同的浏览器编写不同的代码。
  - **阻碍行业发展**：这种“你做你的，我做我的”的做法，最终导致整个行业的发展受到阻碍，重复劳动大量增加，整个生态系统变得混乱。

总而言之，**当前 LLM 领域的“浏览器大战”局面，主要是由于各厂商为了竞争优势而采取差异化的技术标准和方法，导致技术标准不统一，增加了开发者的负担，阻碍了行业的标准化和健康发展**。



