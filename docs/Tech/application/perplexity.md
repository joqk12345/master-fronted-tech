## Perplexity AI创始人访谈

>从检索到解答：Perplexity的直接性革新
不同于传统搜索引擎依赖关键词匹配罗列网页链接，Perplexity采用先进的人工智能集成技术，通过深入分析互联网的链接结构，精准捕捉那些蕴含高质量答案的页面。它不满足于简单呈现搜索结果，而是致力于直接提供答案和信息的综合解读，让用户即刻获得所需的知识与洞见。

>  Wikipedia式的智慧传承
借鉴Wikipedia的综合性与权威性，Perplexity以类似的方式构建响应体系，确保每一次查询都能得到结构化且易于理解的反馈。这种设计不仅增强了信息的可靠性，也让复杂的概念变得通俗易懂，即便是深奥的专业知识，也能轻松掌握。

> 学术级别的严谨排名
 灵感源自学术引用图谱，Perplexity创新性地将“被引次数”纳入其排名算法之中，这意味着那些被广泛认可和引用的内容将在搜索结果中占据更显著的位置。这一机制确保了信息的权威性和时效性，让用户在海量数据中迅速定位到最具价值的资源。

> 速度与细节的双重追求
 深知现代用户对于效率的重视，Perplexity在设计之初便将降低延迟、优化体验放在首位。通过不断的技术优化与算法迭代，确保查询过程流畅无阻，即使是最细微的需求变化，也能迅速反应，为用户带来近乎即时的满意答案。



### 公司的起源故事

Perplexity公司的起源故事始于其创始人Aravind Srinivas与伙伴Dennis和Johnny共同的愿望：利用大型语言模型（LLMs）开发酷炫的产品。在那个时期，虽然还不清楚价值会在模型本身还是产品应用上体现，但像GitHub Copilot这样的生成模型已经开始从研究项目转变为面向用户的实际应用，这激发了他们的灵感。Copilot作为一个编程辅助工具，能够自动生成代码，广受用户欢迎，包括Aravind本人在内，他见证了身边许多人包括Andrej Karpathy在使用并为这项服务付费。这标志着首次AI成为了产品核心，而不只是其他更大体系中的一小部分。

Aravind特别提到，他希望创立的公司能够拥有“AI完整性”，即公司的工作能直接从AI的进步中获益，从而产品得到改进，吸引更多用户，进而创造更多数据，形成良性循环。他认为Google搜索和自动驾驶汽车是两个成功实现这一循环的产品示例，两者都能直接得益于AI技术的发展，提升用户体验。

最初，Aravind曾向首位投资人Elad Gil提出颠覆谷歌搜索引擎的想法，通过类似于Google Glass的方式，让用户通过视觉输入而非键盘进行搜索。虽然这一宏伟愿景得到认可，但Elad建议他们先聚焦一个小的切入点，逐步向更宏大的目标前进。于是，团队决定探索之前无法进行搜索的领域，比如表格和关系数据库的查询。

Perplexity团队发现，以往人们无法以自然语言形式直接查询这些数据库，而必须手动编写复杂的SQL语句。随着GitHub Copilot等项目的成功，他们意识到可以利用语言模型将自然语言问题转换为SQL查询，从而革新数据库查询体验。他们通过抓取数据填充数据库，并训练模型以理解和生成相应的SQL指令。尽管起初他们认为SQL查询的输出熵较低，更易于模板化处理，但后来发现这个假设并不完全正确，过程中遇到了诸多挑战，包括错误处理和重试机制的建立。

他们构建的原型系统能够针对Twitter数据进行搜索，展示出前所未有的查询能力，如查找用户间共同关注的人或共同点赞的推文等。该系统得到了Yann LeCun、Jeff Dean、Andrej Karpathy等知名人物的认可，帮助团队吸引了人才，尽管初期并未得到广泛重视。Aravind分享了他们如何通过生成电话号码和研究提案利用GPT创建虚假学术账户以获取大量推文数据，以及如何在Twitter社交图谱中挖掘有价值信息。

Aravind总结道，向外界展示前所未有的事物，尤其是兼具实用性和魔幻色彩的创新，能够强有力地吸引投资者和顶尖人才的关注。人们对了解自己和周围世界的社交关系充满好奇，这促使Perplexity的第一个版本迅速走红，用户纷纷输入自己的社交媒体账号进行查询，即便有时系统会生成一些令人啼笑皆非的结果，也意外地促进了产品的病毒式传播。

### Perplexity是如何工作的

Perplexity是一个由Aravind Srinivas介绍的新型答案引擎，它结合了搜索引擎和大型语言模型（LLM）的功能，以提供基于来源的答案。与传统搜索引擎不同，Perplexity不仅提供链接列表，而是直接给出经过整理的答案，并附有适当的引用，类似于学术写作中的引用方式。这种设计源于Aravind Srinivas在撰写学术论文时的经验，即每一句话都应有来源支持。

Perplexity的工作流程是，首先使用传统搜索引擎技术提取与用户问题相关的结果，然后从这些链接中提取相关段落，并将这些段落输入到LLM中。LLM会根据这些段落和用户的查询，生成一个格式良好、带有适当脚注的答案。这种设计确保了答案的准确性和可靠性，因为它们都是基于互联网上可验证的信息来源。

Aravind Srinivas和他的团队在创业初期面临许多问题，这些问题促使他们开发了Perplexity。他们意识到，要使聊天机器人提供准确的信息，就必须让它只说出能够在网上找到并有多个来源支持的内容。这种需求促使他们回顾了学术背景，并思考如何防止在同行评审的论文中说出无根据的话。

Perplexity不仅仅是一个更智能的模型，它还涉及到搜索层面、来源层面以及如何将答案格式化并呈现给用户。Aravind Srinivas将Perplexity视为一个知识发现引擎，而不仅仅是一个搜索引擎。他认为，获取答案后的探索过程才是知识旅程的开始，Perplexity通过在答案下方提供相关问题，鼓励用户深入挖掘和提问。

在与Lex Fridman的对话中，Aravind Srinivas强调了Perplexity与传统搜索引擎的区别，尤其是在提供直接答案和综合信息方面。他还提到了Perplexity如何生成相关问题，以激发用户的好奇心并扩展他们的知识。这种设计体现了David Deutsch在其著作《无限开始》中提出的观点，即新知识的创造始于好奇心的火花，寻求解释，然后发现新现象或加深对已有知识的理解。

### RAG

Perplexity的核心技术细节主要围绕检索增强生成（RAG）框架展开，这是一种旨在提高答案生成质量的方法。Aravind Srinivas解释说，RAG的基本原理是：面对一个查询，首先检索相关文档，并从每个文档中挑选相关段落，然后利用这些文档和段落来为查询编写答案。Perplexity在此基础上进一步强化，要求系统只基于检索到的信息作答，若检索信息不足，则坦诚告知用户无法给出满意答案，确保回答基于事实且可追溯至互联网上的文本源头。

在RAG的应用中，系统通过查询进行搜索以增加生成答案时的上下文信息，强调严格遵循网络上人类编写的文本真实性。尽管采取了这些控制措施，系统仍可能产生“幻觉”（hallucinations），即生成不准确或无根据的信息。幻觉产生的原因多样，包括模型理解深度不足、索引质量差、过时或信息不充分的页面被检索，以及模型接收到过多细节难以区分哪些是必要信息等。

为了减少幻觉现象，Perplexity不断优化多个维度：改进检索算法、提高索引质量和页面新鲜度、调整摘要的详细程度，并提升模型处理文档的能力。Aravind指出，通过综合改善这些方面，产品性能可以持续提升。

关于索引过程，Perplexity使用名为PerplexityBot的网络爬虫遍历网页，这涉及到复杂的决策过程，如确定哪些网页和域名加入爬取队列、频率安排、遵循网站的robots.txt文件规则等。爬虫还需处理现代网页常见的JavaScript动态渲染内容，提取有用信息。此外，系统需决定重新爬取的周期，并基于链接发现新页面加入索引队列。

索引建立后，还需要对抓取的内容进行预处理，转化为可被排名系统处理的形式。这个阶段可能涉及机器学习方法进行文本提取，如Google的Now Boost系统。对于如何将网页内容转换为适合存储和检索的格式，Aravind说明并非所有信息都必须以向量形式存储，传统信息检索技术如TF-IDF和BM25算法依然发挥着重要作用，甚至在某些情况下优于基于向量的检索方法。

综上所述，Perplexity的工作机制结合了先进的语言模型技术和传统的信息检索策略，通过细致的索引构建、智能的检索增强生成，以及对多种数据结构和检索算法的灵活运用，力图在保证回答准确性和信息可靠性的同时，提供创新的搜索体验。

### 与Google的对比

在与Aravind Srinivas的对话中，Lex Fridman探讨了新兴搜索引擎Perplexity AI与业界巨头Google之间的比较及其各自的优劣势。Fridman对Perplexity AI在直接回答问题、AI生成的内容摘要、聚焦搜索和用户体验方面的优势表示赞赏，但也指出了其在准确性和速度上的不足。相比之下，Google在速度、即时信息提供（如体育比分）以及对于简单导航查询的处理上更为高效可靠。

Srinivas强调，尽管Google在速度方面占优，能几乎瞬间呈现链接结果，但Perplexity在提供答案时存在延迟。他指出，对于某些特定查询，如天气查询，用户可能期望搜索引擎不仅能提供即时信息，还能根据地点自动定位并给出更具体的建议，如着装推荐，而无需用户明确询问。这表明了在产品设计层面，如何最佳地向用户展示信息是一大挑战。

Fridman和Srinivas都认同，个性化服务对于提升用户体验至关重要，而实现这一目标并不一定需要无限的记忆或上下文窗口，通过用户的地理位置、性别以及常访问的网站等基本信息就能实现相当程度的个性化体验。他们还讨论到，基于人类行为的可预测性，通过有限的关键特征向量即可捕捉用户的大部分需求。

关于Perplexity能否挑战并超越Google或Bing，Srinivas表示，Perplexity的目标并非直接与这些巨头竞争，而是通过重新定义搜索引擎的用户界面和体验来实现颠覆。他认为，真正的创新在于重新思考为何链接要占据搜索界面的主要位置，并且Perplexity已采取大胆立场，即直接提供答案而非传统链接列表，即便这意味着某些情况下可能会有不准确的答案。Srinivas相信，随着时间推移，随着模型技术的进步和成本效率的提高，Perplexity能够显著减少错误和幻想，即使面对长尾查询也能提供更准确的结果。

最后，Fridman询问了Google依赖广告作为主要收入来源的商业模式，以及为什么这种模式不适合Perplexity。Srinivas提到，虽然广告是Google的重要收入流，但Google作为公司还有其他多种盈利渠道。对于Perplexity而言，探索不同于Google的路径，即避免显示广告而专注于提升搜索质量和用户体验，是其在搜索领域中寻求突破的核心策略。

## 创业过程中受到哪些企业家的启发

### 佩奇与布林

在讨论中，Aravind Srinivas 分享了他对谷歌及其创始人拉里·佩奇和谢尔盖·布林的深刻见解。他特别提到了谷歌在早期互联网时代如何通过创新思维脱颖而出。Aravind 强调，与当时的其他搜索引擎不同，谷歌没有遵循传统的文本相似性和信息检索路径，而是采取了一种革命性的方法——PageRank。这一算法通过分析网页之间的链接结构来评估网页的重要性，而非仅仅依赖于文本内容。这种思维方式的转变，即不直接竞争而选择另辟蹊径，为谷歌的成功奠定了基础。

Aravind 进一步指出，佩奇和布林深厚的学术背景对谷歌的发展起到了关键作用。他们从学术引用图谱中获得灵感，这同样影响了Aravind自己的项目Perplexity。Perplexity也利用了类似的思想，即通过追踪领域内的引用情况来构建新的互联网排名模型，不同于谷歌基于点击的排名系统。这种从学术界汲取灵感并应用于产品开发的能力，展示了谷歌创始人将理论知识转化为实用技术的独特能力。

此外，Aravind赞赏佩奇在产品获得用户后所采取的非传统策略。面对互联网泡沫破裂的时期，佩奇选择招聘大量博士而非立即组建商业和营销团队，利用市场低谷获得顶尖人才，如杰夫·迪恩等，专注于核心基础设施和深入研究。佩奇对于延迟时间（latency）的痴迷也是谷歌成功的关键因素之一。他坚持产品需在低性能设备和网络环境下也能流畅运行，这种对用户体验细节的极致追求，使得谷歌的产品即使在最恶劣的条件下也能提供良好的使用体验。

讨论还涉及到了“用户永远没错”这一理念，这是拉里·佩奇推崇的原则，意味着产品设计应始终围绕用户需求和体验进行，即便用户的查询不完美，系统也应能理解其意图并给出高质量答案。Aravind认为，长远来看，产品的目标应该是预判用户需求，在用户提出请求之前就提供服务，而非依赖于用户成为熟练的查询构造者。

综上所述，Aravind Srinivas 从谷歌和其创始人身上学到了多个重要教训：敢于颠覆常规、结合深厚学术背景进行创新、重视技术和人才的投资、对用户体验细节的极致追求，以及始终坚持用户中心的设计哲学。这些原则不仅塑造了谷歌的成功，也为其他科技企业提供了宝贵的经验和启示。

### 杰夫·贝佐斯

从贝佐斯身上，Aravind学到了追求思想的清晰度，即便在初创公司忙碌的日常中，也会偶尔撰写策略文件以帮助自己和团队明确方向和目标，而不是为了分享文档或形式上的工作感。他还强调了会议效率的重要性，认为应该明确会议目的，快速决策，比如在考虑员工薪酬时，如果这个人能为公司带来巨大价值，就不应过分纠结于几万美元的薪资差异，而应将精力放在解决其他更关键的问题上。此外，Aravind提到了贝佐斯对顾客的执着关注，如域名relentless.com重定向到amazon.com的例子，显示出他对客户服务的不懈追求。

随后，Aravind指出所有成功创业者共有的特质是坚持不懈，并且对用户有着近乎痴迷的关注。他引用了贝佐斯的一个观点，即不论是互联网公司还是其他，最关键的是顾客。这表明Aravind在构建产品时，更重视最终结果是否满足用户需求，而非拘泥于技术实现的细节，例如在面对“你是做封装还是自建AI模型”的问题时，他的回答是两者兼具，但最重要的是产品能有效、快速、准确地服务于用户，使AI普及到每个人的生活中，让用户无需关心背后的技术细节。

### 埃隆·马斯克

Aravind表示从他身上学到了坚韧不拔的精神。当外界普遍认为某些事情难以实现时，马斯克却能无视质疑，凭借意志力坚持推进。这种即使面对重重困难也不放弃的态度，体现了通过纯粹的决心和意志克服挑战的能力，这也是Aravind十分钦佩并努力效仿的品质。

在任何商业活动中，分销都是最为艰难的一环。通过阅读沃尔特·艾萨克森关于他的传记，我们可以了解到，依赖他人进行产品分销可能会导致一些问题。以他最初创立的公司Zip2为例，该公司试图打造类似谷歌地图的服务，最终虽与其他网站合作，将技术嵌入到它们的平台上，但却失去了与用户的直接联系。尽管这样的合作模式能够带来收入，但从长远看不利于企业自身发展。而在特斯拉的运营中，马斯克采取了截然不同的策略，没有通过经销商，而是直接与用户建立联系。虽然这样做的风险在于可能难以迅速扩大规模，但令人惊叹的是，他成功实现了这一模式。由此可见，那种不屈不挠的意志力以及“没有任何工作是卑微的”这一原则性思考至关重要。据说，在自动驾驶项目Autopilot中，马斯克甚至亲自参与数据处理，以便深入了解其运作机制。每一个细节都可能是做出正确商业决策的关键，而他在这一点上表现得极为出色。

了解每一个细节不仅能帮助突破难题，还能简化系统。当你深入了解每个人实际在做什么时，自然会问到根本性的问题：我们为何要这样做？是否存在冗余或不必要的环节？比如在数据标注上，为何采用当前的方式？是否界面设计不够高效？或者，我们为何需要人工标注？难道不能采用自我监督学习的方法吗？不断地追问“为什么”，挑战既定方式，探索是否有可能以更简单的方式达成目标，是推动进步的重要途径。

### 扎克伯格

扎克伯格以“快速行动，打破陈规”闻名，他的这种对速度的追求给Aravind留下了深刻印象。

对于扎克伯格在开源领域的领导地位，Aravind表示非常赞赏。作为一家在该领域内创业的公司，Aravind认为Meta及扎克伯格在人工智能领域的开源贡献是非常宝贵的。尽管扎克伯格因社交媒体领域的一些争议而备受关注，但他在人工智能和模型开源方面站在前沿的立场，尤其是发布如Llama-3-70B这样接近顶尖水平的模型，其质量接近GPT4，尽管在处理长尾问题上略逊一筹，但在大多数应用场景中已非常接近。而且，尚未发布的4或50亿参数版本模型，有潜力超越现有水平，即便效率略低也无关紧要。扎克伯格的这些举措极大地改变了行业格局，让人们对未来可能出现更多竞争者而非仅由两三家公司掌控最先进模型的局面充满希望。因此，Aravind认为扎克伯格的成功不仅对其自身至关重要，也将为许多其他企业创造成功的机会。

### Yann LeCun

Yann LeCun作为Perplexity项目的自助者，Aravind表达了对Yann LeCun的极大尊重，指出尽管多年间他的工作曾被低估或嘲笑，但他仍然坚持不懈。LeCun对卷积神经网络（Convnets）、自监督学习、能量模型等领域有着重要贡献，并培养了一批杰出的科学家，如DeepMind首席技术官Koray Kavukcuoglu、OpenAI的联合创始人Wojciech Zaremba以及DALL-E的发明者Aditya Ramesh等。

Aravind特别提到了LeCun在2016年的前瞻性观点，当时强化学习（RL）正炙手可热，而LeCun却在欧洲顶级人工智能会议上提出，强化学习只是蛋糕上的樱桃，大部分智能实际上藏在蛋糕主体之中，即无监督学习（后来被广泛称为自监督学习），而监督学习则是蛋糕上的糖霜。这一论断后来被证明与ChatGPT等模型的成功配方相符，即大量计算资源用于预训练以预测下一个令牌，这是自监督学习的核心，而监督微调则是蛋糕上的糖霜，赋予了模型对话能力。

Aravind还指出，尽管LeCun在当时对生成对抗网络（GANs）的押注并未成为主流，但他的核心洞察——即大部分计算资源应投入从原始数据中学习，而非过分依赖强化学习——是极具前瞻性和争议性的。如今，LeCun又提出了另一个富有争议的观点，即自回归模型可能是一个死胡同，暗示未来可能需要在更抽象的表征空间中进行推理，再利用自回归或扩散模型解码回原始输入空间，这样的方法可能更加高效。

关于人工智能安全问题，LeCun主张开放源代码是保持AI安全的解决方案，这一观点同样引发争议。Aravind同意这一看法，认为如果有潜在危险，让更多人审查反而更安全。Lex Fridman则指出，虽然历史表明新技术往往会引发类似的担忧，但最终工程师们的直觉往往贴近实际，开放源代码至少目前看来是最佳途径，因为它最大化了透明度并集合了最多智慧来共同解决问题，包括如何预防模型被滥用。

Aravind补充道，开放源代码能让人们更快发现系统可能被误用的方式，并建立相应的防护措施，同时促进学术界基于模型权重的突破，进而推动整个领域的发展。许多技术爱好者乐于探究如何防止系统出错，这种透明度和合作精神对于AI的安全发展至关重要。

## AI的突破性革命

在探讨自注意力机制（self-attention）对人工智能领域带来革命性影响的过程中，Aravind Srinivas追溯了这一概念的起源与发展。他提到，Yoshua Bengio与其学生Dzmitry Bahdanau发表的关于软注意力（Soft Attention）的论文首次在“对齐与翻译”模型中应用了这一概念，展示了注意力机制在机器翻译任务中的优越性。尽管Ilya Sutskever通过大规模RNN模型取得了显著成果，但其方法依赖于大量的计算资源。而Bahdanau的工作通过引入注意力机制，以更少的计算量超越了先前的性能，显示了注意力机制的巨大潜力。

随后，DeepMind的研究人员在Pixel RNNs论文中提出，甚至不需要使用循环神经网络（RNNs），通过完全卷积模型结合掩码技巧进行自回归建模，WaveNet架构因此诞生，极大地提升了模型训练的并行性与效率。Google Brain团队随后在Vaswani等人发表的Transformer论文中，结合了注意力机制与全卷积模型的优点，创造了Transformer架构，该架构自2017年以来几乎未发生重大变化，仅在非线性函数和缩放策略上有所改进。

Aravind强调，注意力机制使得模型能够学习更高阶的依赖关系，而Transformer通过自注意力运算，无需参数即可执行大量浮点运算，从而更高效地利用硬件资源。OpenAI在此基础上进一步推进，认识到无监督学习的重要性，通过Sentiment Neuron和GPT-1等项目，展示了大规模语言模型在自然语言理解上的潜力。随着GPT系列的发展，尤其是GPT-3通过增加数据规模和模型参数，以及使用通用爬虫数据，实现了前所未有的性能提升。

Aravind指出，这一系列进展不仅仅是注意力机制本身的胜利，而是并行计算、Transformer架构、无监督预训练、高质量数据集以及持续评估优化等多个因素共同作用的结果。他还提到了后训练阶段（post-training）的重要性，如基于强化学习的微调（RLHF）对于提高模型可控性和行为表现的关键作用，以及检索增强（Retrieval-Augmented）架构等新研究方向，旨在探索如何让模型像参加开卷考试一样，高效地结合事实与推理能力。

最后，他提到了微软等机构正在探索的小型语言模型（SLMs）研究，旨在仅针对推理任务所需的重要标记进行训练，试图找到一种减少对大规模预训练数据依赖的新路径，这可能会颠覆当前基于基础模型的方法，开启人工智能发展的新篇章。

### AI未来

Lex Fridman与Aravind Srinivas讨论了人工智能领域的一个潜在发展方向，即通过后训练（post-training）过程实现智能爆炸的可能性。他们认为，尽管很难断言这种情况不可能发生，但实际上需要解决的问题是如何在没有新的人类注释信号的情况下，AI系统能够自我学习和提升。在棋类游戏的自我对弈中，胜负结果提供了明确的反馈信号，但对于更开放的任务，如预测股市走向，正确答案并不明确，这时可能需要依赖历史数据或人类验证者的确认。

Aravind指出，实现类似人类自我提升的循环可能需要一个强化学习的沙盒环境，让AI代理在其中执行任务，根据任务完成情况（由人类评估）获得反馈信号。尽管目前尚未实现这种程度的自主学习，但所有必要的技术要素似乎已经具备，特别是在AI系统被广泛使用且人类互动频繁的当下，这使得这一设想看似并不遥远。

Aravind还谈到了AI是否能实现人类级别的推理能力，特别是像爱因斯坦或费曼那样，面对难题时能够自我探索、深入研究并给出惊人答案的能力。他认为，若AI能通过增加推理计算量来大幅提高答案质量，那将是真正推理能力突破的开始。然而，他强调了人类好奇心的特殊性，认为即使AI能够模拟高级推理，人类的好奇心仍驱动着AI去探索未知，提出有趣的问题并深入研究。目前，AI尚未掌握这种自然好奇心的本质。

他们还提到了加州大学伯克利分校教授Alyosha Efros的研究，展示了在缺乏奖励信号的情况下，基于预测误差的探索如何使AI代理完成游戏任务，但这仅限于游戏层面，还未真正模仿人类的好奇心。即使将来某天AI达到了强人工智能（AGI）水平，能够像费曼一样进行科学对话，Aravind也不确定AI能否复制费曼那种广泛的、天然的好奇心，那种驱使他深入探究众多不同领域并寻求正确问题解释的好奇心。因此，尽管技术进步在不断推动AI向更高级的认知功能发展，但真正模仿人类复杂情感和思维特质的挑战依然存在。

### 一万亿美元的问题

在讨论中，Lex Fridman与Aravind Srinivas构想了一个未来场景，其中人工智能（AI）能够持续提出并解答相关问题，形成知识探索的链条，类似于人类的好奇心驱动的探索过程。他们认为，如果AI能够自主探索世界、提出问题并给出创新答案，这将是一个重大的飞跃。特别是，如果AI能够在诸如药物设计等复杂领域中，通过长时间的迭代计算（所谓的“推理计算”）给出全新的解决方案，其价值可能是巨大的，甚至达到数万亿美元级别。然而，这也引发了对计算资源集中化及其潜在社会影响的担忧，因为并非所有人都能负担得起进行此类高级研究所需的庞大计算成本。这意味着，未来AI的进步不仅受限于技术和数据，还受限于谁能够访问和支付得起进行这些高阶推理所需的计算资源。

两人进一步讨论了强人工智能（AGI）的实现路径，认为一旦解决了“先天”部分，即通过预训练获得基本能力，接下来的关键在于“后天”的快速迭代思考能力，这需要强大的计算支持。他们强调，真正的挑战在于如何让AI产生新的知识，如同优秀博士生在学术界所做的那样，提出具有重大影响力的科研成果，或者如同伽利略和哥白尼那样，质疑现有认知并提出新的理论。

此外，他们还讨论了AI产生真正创新想法的时间表，认为这不太可能是一个单一的突破时刻，而是需要一系列小步快跑式的进展，特别是在如何有效利用连续的计算资源来提升问题解决能力方面。他们期待看到AI在解决目前尚存争议或理解不深的现实问题时，展现出更深层次的理解力，甚至能够揭示出我们未曾预料到的真相。这种能力的显现，无论是在科学发现还是技术创新领域，都将是AI向AGI迈进的重要标志。然而，他们也指出，目前的AI系统尚未显示出能够实现这类突破的迹象，因此对何时能达到这一里程碑仍难以准确预测。

### 一百万块H100 GPU的数据中心

在讨论关于谁最有可能率先建造相当于一百万块H100 GPU的数据中心时，Aravind Srinivas提到他在推特上发起了一项投票，选项包括谷歌、OpenAI（实际上代表的是与微软的合作）、Meta以及一个未知的X选项。由于推特的限制，他未能将Anthropic或亚马逊等其他重要玩家纳入投票中。百万这个数字更多地是一种象征，代表了一个大规模计算能力的里程碑。Aravind强调，这种规模不仅限于具体的硬件数量，也关乎下一代GPU以更低能耗实现同等或更优计算能力的可能性。他还提到，无论是在研究高度先进的AI系统还是探索模型自我推理等方向，大量的GPU计算资源都是至关重要的。

在通往通用人工智能（AGI）的竞争中，是否掌握最大计算能力就意味着“胜利”。对此，Aravind认为当前局势似乎正朝着这个方向发展，前沿模型的竞赛确实聚焦于计算能力的比拼。然而，任何技术突破都可能改变这一局面。如果能实现推理与事实的解耦，创造出规模虽小但推理能力强的高效模型，那么对百万H100 GPU级别集群的需求就不再是必要条件。

Aravind进一步阐述，关键在于如何以更高效、更抽象的方式表示知识，并使推理过程变得迭代且参数独立，这意味着要在如何高效编码知识和执行高效推理上寻求创新，从而可能颠覆当前依赖大规模计算资源的传统路径。


### 给创业者建议

Aravind Srinivas在分享创立公司时的建议时强调，传统智慧如不懈的毅力、坚韧不拔的精神、自信以及对他人的信任仍然至关重要。他认为，创业者往往在决定创业后容易犯的一个错误是去追求市场看似需要的东西，而不是自己真正热爱的想法。Aravind建议从自己热爱的领域开始，确保这是你愿意在没有即时回报的情况下持续努力的产品。只有真正对所做的事充满热情，才能在解决难题的过程中坚持下去，因为这不仅仅是追求金钱回报，而是相信所做的事业具有深远的意义。

关于创业过程中的成本、牺牲和痛苦，Aravind指出，这些是不可避免的，因此建立良好的支持系统至关重要。他个人的支撑来自于家庭，尤其是非常支持他的妻子，他们共同对项目充满热情，这种情感纽带成为他前进的动力。他认为，伟大的成就往往伴随着牺牲和全心全意的投入。虽然艰难，但意识到能够通过自己的产品服务数百万人是一种幸运，这种认识会激励人努力维持并扩大这一成果。

关于创业初期的挑战，Aravind提到，优秀的创始人往往需要面对众多可能导致失败的可能性，但他们仍然选择坚持，因为他们相信自己所做的事情至关重要。他引用了《复仇者联盟》中的一幕，其中一个人物找到了百万种可能性中唯一的生存之路，以此比喻创业的艰难与机遇并存。

对话中还提及了年轻时努力工作的重要性，尤其是在二十几岁的时候，这段时间是积累经验和技能的黄金时期。Aravind鼓励年轻人如果有一个想法始终占据心头，就应该为之付出努力，至少在年轻的时候应该全身心投入到这个想法中。他认为，即使最终没有达到预期，至少不会留下遗憾，因为曾全力以赴尝试过。同时，他也提醒要合理利用时间，与志同道合的人为伍，相互激励，追求卓越。

最后，关于如何平衡工作与生活，Aravind强调了明确个人目标的重要性。他不主张每个人都必须拼命工作，但如果你对某个目标有极高的热情，就应该勇于为此投入时间和精力，特别是在年轻时，因为这段时间的努力可以为未来奠定坚实的基础。他还分享了自己曾经后悔没有充分利用每一刻的经历，以此作为对年轻人珍惜时间、积极投入的鼓励。

### AI的未来

Lex Fridman 和 Aravind Srinivas 探讨了人工智能（AI）在人类生活中可能扮演的深度角色，包括与人类形成深层次联系甚至浪漫关系的可能性。尽管Aravind承认像Replika这样的应用以及一些展示出类似人类互动特征的AI已经存在，暗示了这类未来场景的可能性，但他更希望看到的是AI帮助人们提高工作效率，让人们有更多时间去建立真实的人际连接，而非完全替代人际交往。他强调，当工作变得不再像工作，而是一种自我实现和满足时，人们能更自由地追求兴趣，与他人建立深厚的关系，并对地球的未来持乐观态度。

Lex同意，当人们在工作之外与AI交流如同与深刻理解他们的朋友一样，这可以增强人类之间的关系。他指出，高质量的友谊能够提供一种治疗效果，让人可以坦诚相待，展现脆弱性，AI若能以这种方式辅助，可能会带来正面影响。

然而，他们也认识到人性的复杂性，包括阴暗面和心理阴影，这些可能无法仅凭好奇心来解决。Aravind期望，随着智能和知识的丰富，零和思维模式会减少，因为人们不再感受到资源的稀缺。他坚信，AI作为个人教练或引导者，帮助人们理解并达成生活中的真正目标，将是极其有益的，而非仅仅模仿人类情感的伴侣。

两人还讨论了AI在促进理解、减少偏见方面的作用，认为AI可以帮助人们更好地理解周围的世界，包括不同人群和观点，从而在根本上促进和平与爱。他们共同寄望于AI能够成为增强人类好奇心、扩展知识边界、促进全球理解与和谐的重要工具。

对话结束时，Lex感谢Aravind启发人心的谈话，特别是他通过创建Perplexity在AI领域所做的贡献，而Aravind则对有机会进行这样富有启发性的对话表示感谢。整个对话以爱因斯坦的名言作结，强调了持续提问和保持好奇心的重要性，这正是推动科技进步和社会发展的关键动力。

